{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1633a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f082f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42addddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device for Train : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Device for Train : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88224fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a505e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.cache',\n",
       " '.jupyter',\n",
       " '.bashrc',\n",
       " '.conda',\n",
       " '.local',\n",
       " '.ipython',\n",
       " '.config',\n",
       " '.ipynb_checkpoints',\n",
       " 'conts_elec_start.py',\n",
       " 'predict.py',\n",
       " 'preprocessing.py',\n",
       " 'conts_elec_main.py',\n",
       " '2. 연락처모델_학습(0130).ipynb',\n",
       " '1. 무성의모델_학습(0127).ipynb',\n",
       " 'utils',\n",
       " '.nv',\n",
       " 'elec',\n",
       " '무성의모델학습데이터(0127).csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f78444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자기소개요??? 딱히 할 말이 없는데요 잘 모르겠어요 음음 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>하하라라한사라라라라라안녕하세요? 좋은하루되세요 전 가요오옹##</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인상좋음나는대학졸업후사진작갈활동하며수많은연예인을찍었다성실하고착한성품을지녰다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2남1녀중장남조묭한여자가좋음만나면즇은이미지로사길것임니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다여님 아 그리고 이 책은 물론 이 모든 것을 다 같이 보내드립니다 수 있는 것입니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63894</th>\n",
       "      <td>길을걷다바지주머니에손을넣고입에담배한개피를물고터보라이터를잡았을때정말우연히하늘아래나에게...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63895</th>\n",
       "      <td>부모님 하고 동생  있습니다!!!!!!!ㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63896</th>\n",
       "      <td>Nhà tôi có 5 người bố mẹ chị gái em gái và tôi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63897</th>\n",
       "      <td>지금가족은제딸들뿐이고요친척들은연락안한지오래되어서연락도안될뿐드러친척이어디에어디서무엇을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63898</th>\n",
       "      <td>이남일녀중둘째로태어나군에제대하고국내외여행업및전세버스운송사업하다가오년전에쫄닭망하고재기...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63899 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   conts  label\n",
       "0                    자기소개요??? 딱히 할 말이 없는데요 잘 모르겠어요 음음 ㅋㅋ      0\n",
       "1                     하하라라한사라라라라라안녕하세요? 좋은하루되세요 전 가요오옹##      0\n",
       "2              인상좋음나는대학졸업후사진작갈활동하며수많은연예인을찍었다성실하고착한성품을지녰다      0\n",
       "3                         2남1녀중장남조묭한여자가좋음만나면즇은이미지로사길것임니다      0\n",
       "4      다여님 아 그리고 이 책은 물론 이 모든 것을 다 같이 보내드립니다 수 있는 것입니...      0\n",
       "...                                                  ...    ...\n",
       "63894  길을걷다바지주머니에손을넣고입에담배한개피를물고터보라이터를잡았을때정말우연히하늘아래나에게...      0\n",
       "63895                부모님 하고 동생  있습니다!!!!!!!ㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣㅣ      1\n",
       "63896     Nhà tôi có 5 người bố mẹ chị gái em gái và tôi      0\n",
       "63897  지금가족은제딸들뿐이고요친척들은연락안한지오래되어서연락도안될뿐드러친척이어디에어디서무엇을...      0\n",
       "63898  이남일녀중둘째로태어나군에제대하고국내외여행업및전세버스운송사업하다가오년전에쫄닭망하고재기...      0\n",
       "\n",
       "[63899 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('무성의모델학습데이터(0127).csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d316ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13567fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_df = mu_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4234f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conts    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55caa30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748b467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32841, 2) (30871, 2)\n"
     ]
    }
   ],
   "source": [
    "label_0 = mu_df.loc[mu_df['label']==0]\n",
    "label_1 = mu_df.loc[mu_df['label']==1]\n",
    "\n",
    "print(label_0.shape, label_1.shape)\n",
    "\n",
    "final_mu_df = pd.concat([label_0, label_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f25dddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50970, 2) (12742, 2)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 : 검증 데이터 8:2\n",
    "\n",
    "train_data = final_mu_df.sample(frac=0.8, random_state=2022)[['conts','label']]\n",
    "test_data = final_mu_df.drop(train_data.index)[['conts','label']]\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f482077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"beomi/KcELECTRA-base-v2022\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6991e947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['[CLS]', 'ㅅ', '##ㅅ', '##듣', '##ㅎ', '##ㄴ', '##ㄷ', '##ㅈ', '##ㅎ', '##ㄴ', '##ㄷ', '##ㅎ', '##ㄴ', '##ㄷ', '##ㅈ', '##ㅎ', '##ㄷ', '##ㅈㅇ', '##ㅅ', '##ㄷ', '##ㅈ', '##ㅅ', '##ㄴ', '##ㅈ', '##ㅅ', '##ㄴ', '##ㅈ', '##ㅎ', '##ㄷ', '##ㅈㅇ', '##ㅅ', '##ㅈ', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[2, 362, 4361, 4458, 4407, 4700, 4322, 4406, 4407, 4700, 4322, 4407, 4700, 4322, 4406, 4407, 4322, 31362, 4361, 4322, 4406, 4361, 4700, 4406, 4361, 4700, 4406, 4407, 4322, 31362, 4361, 4406, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# train dataset 토크나이징\n",
    "tokenized_train_sentence = tokenizer(\n",
    "    list(train_data['conts']),\n",
    "    max_length=128,\n",
    "    return_tensors='pt',  #pyotorch의 tensor 형태로 return\n",
    "    padding=True,        #제로패딩 설정\n",
    "    truncation=True,     # max_length 초과 토큰 truncate\n",
    "    add_special_tokens=True)  # special token 추가\n",
    "\n",
    "\n",
    "print(tokenized_train_sentence[0])\n",
    "print(tokenized_train_sentence[0].tokens)\n",
    "print(tokenized_train_sentence[0].ids)\n",
    "print(tokenized_train_sentence[0].attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00fa919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset 토크나이징\n",
    "tokenized_test_sentence = tokenizer(\n",
    "    list(test_data['conts']),\n",
    "    max_length=128,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f05898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=128, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['[CLS]', '자기', '##소개', '##요', '?', '?', '?', '딱히', '할', '말이', '없는데', '##요', '잘', '모르겠', '##어요', '음음', 'ㅋㅋ', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[2, 8054, 33372, 4134, 33, 33, 33, 19173, 3459, 8235, 9001, 4134, 2729, 12159, 8136, 43444, 7974, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_test_sentence[0])\n",
    "print(tokenized_test_sentence[0].tokens)\n",
    "print(tokenized_test_sentence[0].ids)\n",
    "print(tokenized_test_sentence[0].attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea6127da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset) :\n",
    "    def __init__(self, encodings, labels) :\n",
    "        self.encodings = encodings\n",
    "        print(self.encodings)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.labels)    \n",
    "        \n",
    "    def __getitem__(self, idx) :\n",
    "        item = {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65b091da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,   362,  4361,  ...,     0,     0,     0],\n",
      "        [    2,  8969,  9661,  ...,     0,     0,     0],\n",
      "        [    2,    71,  4545,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  8213,  8679,  ...,     0,     0,     0],\n",
      "        [    2,     1,     3,  ...,     0,     0,     0],\n",
      "        [    2, 26907, 13529,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'input_ids': tensor([[    2,  8054, 33372,  ...,     0,     0,     0],\n",
      "        [    2,    25, 47027,  ...,     0,     0,     0],\n",
      "        [    2,     1,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    64,    64,  ...,     0,     0,     0],\n",
      "        [    2,    18,    18,  ...,     0,     0,     0],\n",
      "        [    2, 39005,  8009,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# dataset 형성(텐서로 변환)\n",
    "train_label = train_data['label'].values\n",
    "test_label = test_data['label'].values\n",
    "\n",
    "train_dataset = CustomDataset(tokenized_train_sentence, train_label)\n",
    "test_dataset = CustomDataset(tokenized_test_sentence, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297bbf91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(54343, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전학습 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07fca0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train option setting\n",
    "train_arguments = TrainingArguments(\n",
    "                    output_dir='./',\n",
    "                    num_train_epochs=5,\n",
    "                    per_device_train_batch_size=64,\n",
    "                    per_device_eval_batch_size=64,\n",
    "                    logging_dir='./logs',\n",
    "                    no_cuda=True,\n",
    "                    logging_steps=500,\n",
    "                    save_total_limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "487b4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def compute_metrics(pred) :\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision = precision_score(labels, preds) \n",
    "    recall = recall_score(labels, preds)\n",
    "    f1 = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy' : acc,\n",
    "        'f1' : f1,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43c6ad9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 3.82 GiB total capacity; 180.05 MiB already allocated; 18.12 MiB free; 182.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:511\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:754\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 754\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1902\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1898\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1899\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1900\u001b[0m     )\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 3.82 GiB total capacity; 180.05 MiB already allocated; 18.12 MiB free; 182.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train\n",
    "train = Trainer(\n",
    "                model=model,\n",
    "                args=train_arguments,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics)\n",
    "\n",
    "train.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b941925",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "50061ce9",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a120b195",
   "metadata": {},
   "source": [
    "### `2차`\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class predictModel() :\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        # load model\n",
    "        self.model_path = model_path\n",
    "        self.model = torch.load(model_path)\n",
    "        # set device\n",
    "        self.device = torch.device('cpu')\n",
    "        # load tokenizer\n",
    "        model_name = \"beomi/KcELECTRA-base-v2022\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_sentence(self, sent):\n",
    "        self.model.eval()\n",
    "#         sent = self.clean_sentence(sent)\n",
    "        # tokenizing\n",
    "        tokenized_sent = self.tokenizer(\n",
    "            sent,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128\n",
    "        )\n",
    "        tokenized_sent.to(self.device)\n",
    "\n",
    "        # prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=tokenized_sent['input_ids'],\n",
    "                attention_mask=tokenized_sent['attention_mask'],\n",
    "                token_type_ids=tokenized_sent['token_type_ids']\n",
    "            )\n",
    "\n",
    "        # result\n",
    "        if len(sent) < 10 :\n",
    "            # 10자 이하는 연락처 로 탐지하지 않음\n",
    "            return 0\n",
    "\n",
    "        result = outputs[0].detach().cpu().argmax(-1)\n",
    "        #     print(outputs[0].detach().cpu())\n",
    "\n",
    "        return int(result)\n",
    "        # 0 : 정상, 1 : ( 무성의 or 연락처 탐지 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = str(datetime.today())[:10]\n",
    "path = f\"{today}_mu_model.pt\"\n",
    "\n",
    "# save model \n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ef6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = str(datetime.today())[:10]\n",
    "path = f\"{today}_mu_model.pt\"\n",
    "\n",
    "# save model \n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c30131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "mod = torch.load(f\"{today}_mu_model.pt\")\n",
    "mod.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d19707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2955158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afc7cb26",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Preprocessing():\n",
    "\n",
    "    def __init__(self, sent):\n",
    "        self.sent = sent\n",
    "\n",
    "    def clean_sentence(self):\n",
    "        try:  # 무성의\n",
    "            self.sent = re.sub('[^\\w\\s]', ' ', self.sent).strip()\n",
    "            self.sent = re.sub('[.,?!ᆢ~]', ', ', self.sent)\n",
    "            self.sent = re.sub('[ㄱ-ㅎ|ㅏ-ㅣ]', 'ㅋ', self.sent)\n",
    "            self.sent = re.sub('니다', '니다. ', self.sent)\n",
    "            self.sent = re.sub('어요', '어요. ', self.sent)\n",
    "            self.sent = re.sub('\\n', ' ', self.sent).strip()\n",
    "\n",
    "        except:\n",
    "            print('clean_sentence method fail')\n",
    "            pass\n",
    "\n",
    "        return self.sent\n",
    "\n",
    "    def f_clean_sentence(self):\n",
    "        try:\n",
    "            self.sent = re.sub('[^\\w\\s]', ' ', self.sent).strip()\n",
    "            self.sent = re.sub('[.,?!ᆢ~]', ', ', self.sent)\n",
    "            self.sent = self.return_text(self.sent)\n",
    "\n",
    "        except:\n",
    "            print('f_clean_sentence method fail')\n",
    "            pass\n",
    "        return self.sent\n",
    "\n",
    "    def sub_num(self, sent):\n",
    "        hannum_list = ['일', '이', '삼', '사', '오', '육', '륙', '칠', '팔', '구', '십', '영']\n",
    "        sent = re.sub(r'[0-9]', ' ', sent)\n",
    "\n",
    "        for i in hannum_list:\n",
    "            sent = re.sub(rf'{i}', '  ', sent)\n",
    "        return sent\n",
    "\n",
    "    def return_target_list(self, pattern, sent):\n",
    "        word_list = []\n",
    "        for i in pattern.finditer(sent):\n",
    "            target_word = sent[i.start(): i.end()]\n",
    "            word_list.append(target_word)\n",
    "        return word_list\n",
    "\n",
    "    def return_text(self, sent):\n",
    "\n",
    "        nam = '[남]+'\n",
    "        nyeo = '[녀]+'\n",
    "        yeo = '[여]+'\n",
    "        son = '[아들]+'\n",
    "        ddal = '[딸]+'\n",
    "        num = '[\\s]*(\\d){1,2}[\\s]*'\n",
    "        han_num = '[일이삼사오육륙칠팔구십]+'\n",
    "\n",
    "        person_list = [nam, son, nyeo, yeo, ddal]\n",
    "        num_list = [num, han_num]\n",
    "\n",
    "        for person_pattern in person_list:\n",
    "            for num_pattern in num_list:\n",
    "                pattern_list = [person_pattern + num_pattern, num_pattern + person_pattern]\n",
    "                target_list = []\n",
    "\n",
    "                for pattern in pattern_list:\n",
    "                    add_pattern = re.compile(pattern)\n",
    "                    m = add_pattern.findall(sent)\n",
    "                    if m != []:\n",
    "                        target_words = self.return_target_list(add_pattern, sent)\n",
    "                        target_list += target_words\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                for i in target_list:\n",
    "                    sent = sent.replace(i, self.sub_num(i))\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class predictModel():\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        # load model\n",
    "        self.model_path = model_path\n",
    "        self.model = torch.load(model_path)\n",
    "        # set device\n",
    "        self.device = torch.device('cpu')\n",
    "        # load tokenizer\n",
    "        model_name = 'beomi/KcELECTRA-base-2022'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_sentence(self, sent):\n",
    "        self.model.eval()\n",
    "        Pr = Preprocessing(sent)\n",
    "\n",
    "        if 'call' in str(self.model_path):\n",
    "            sent = Pr.f_clean_sentence()\n",
    "\n",
    "        else:\n",
    "            sent = Pr.clean_sentence()\n",
    "\n",
    "        # tokenizing\n",
    "        tokenized_sent = self.tokenizer(\n",
    "            sent,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        tokenized_sent.to(self.device)\n",
    "\n",
    "        # prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=tokenized_sent['input_ids'],\n",
    "                attention_mask=tokenized_sent['attention_mask'],\n",
    "                token_type_ids=tokenized_sent['token_type_ids']\n",
    "            )\n",
    "\n",
    "        # result\n",
    "        per = int(str(np.array(F.softmax(outputs[0][0], dim=0).detach().cpu())[1] * 100).split('.')[0])\n",
    "        result = outputs[0].detach().cpu().argmax(-1)\n",
    "\n",
    "        if int(per) >= 99:\n",
    "            return 1\n",
    "        \n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class predictModel():\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        # load model\n",
    "        self.model_path = model_path\n",
    "        self.model = torch.load(model_path)\n",
    "        # set device\n",
    "        self.device = torch.device('cpu')\n",
    "        # load tokenizer\n",
    "        model_name = 'beomi/KcELECTRA-base-2022'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def predict_sentence(self, sent):\n",
    "        self.model.eval()\n",
    "        Pr = Preprocessing(sent)\n",
    "\n",
    "        if 'call' in str(self.model_path):\n",
    "            sent = Pr.f_clean_sentence()\n",
    "\n",
    "        else:\n",
    "            sent = Pr.clean_sentence()\n",
    "\n",
    "        # tokenizing\n",
    "        tokenized_sent = self.tokenizer(\n",
    "            sent,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        tokenized_sent.to(self.device)\n",
    "\n",
    "        # prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(\n",
    "                input_ids=tokenized_sent['input_ids'],\n",
    "                attention_mask=tokenized_sent['attention_mask'],\n",
    "                token_type_ids=tokenized_sent['token_type_ids']\n",
    "            )\n",
    "\n",
    "        # result\n",
    "        per = int(str(np.array(F.softmax(outputs[0][0], dim=0).detach().cpu())[1] * 100).split('.')[0])\n",
    "\n",
    "        if len(sent) <= 5:\n",
    "            # 10자 이하는 연락처 로 탐지하지 않음\n",
    "            return 1, int(per)\n",
    "\n",
    "        result = outputs[0].detach().cpu().argmax(-1)\n",
    "\n",
    "        if int(result) == 0:\n",
    "            return int(result), int(per)\n",
    "\n",
    "        return int(result), int(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e02180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a95b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7933e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eb9c393",
   "metadata": {},
   "source": [
    "## 실 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefcec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "# db 연동\n",
    "conn = pymysql.connect(\n",
    "    user='my_srv',              # 유저 이름\n",
    "    passwd='wkrldi@duqhdi12',   # 패스워드\n",
    "    host='125.141.223.156',     # 호스트\n",
    "    db='m_yeoboya',             # 데이터베이스\n",
    "    charset='utf8',             # 인코딩\n",
    "    port=33141                  # 포트 번호(''없이 사용)\n",
    ")\n",
    "\n",
    "cursor = conn.cursor(pymysql.cursors.DictCursor)\n",
    "sql1 = \"SELECT mem_no, mate_conts, family_conts, list_prt_yn FROM m_yeoboya.member_mate WHERE list_prt_yn='y'\" \n",
    "cursor.execute(sql1)\n",
    "result1 = cursor.fetchall()\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "all_mate_df = pd.DataFrame(result1) \n",
    "\n",
    "# \n",
    "display(all_mate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = all_mate_df.copy()\n",
    "result = result[['mem_no','mate_conts', 'family_conts']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_model = predictModel(model_path = f\"{today}_mu_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dbf60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(range(result.shape[0])):\n",
    "    text = result.loc[row, 'mate_conts']\n",
    "    f_text = result.loc[row,'family_conts']\n",
    "    result.loc[row,'mu_result'], result.loc[row,'mu_per'] = mu_model.predict_sentence(str(text))\n",
    "    result.loc[row,'f_mu_result'], result.loc[row,'f_mu_per'] = mu_model.predict_sentence(str(f_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db7118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd48cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
